#!/bin/bash

#
# s3-to-Awstats
#

##
# configuration
##
log_dir="/data/s3logs/" # directory to store the s3 log files
bucket_name="xenalog" # name of the bucket on s3
#bucket_name="xenabrowserlog" # name of the bucket on s3
bucket_dir="AWSLogs/659676827912/elasticloadbalancing/us-east-1/" # sub directories on the bucket on s3
log_file="/data/s3logs/download-${bucket_name}.log" # file to log this scripts output

##
# download log files from s3
##
#s3cmd sync --skip-existing s3://${bucket_name}/${bucket_dir} ${log_dir}${bucket_name}/ >> $log_file
#s3cmd sync s3://${bucket_name}/${bucket_dir} ${log_dir}${bucket_name}/ >> $log_file

### merge all elb logs into one file
cd /data/s3logs/xenalog

# clean each subdirectory, remove bad lines (multiple download of the same file from the same ip within 1 min), generate cleanMerge in each subdirectory
python s3logcleanup.py /data/s3logs/xenalog

find . -name 'cleanMerge' | xargs cat >> /data/wwwstats/xene/merged_log

#find . -name '*.log' | xargs cat >> /data/wwwstats/xene/merged_log

### make the file the Awstats can understand
# rid of the 6 digits after second and "Z"
sed -ie "s/\(:[0-9]\{2\}\)\(\.[0-9]\{6\}Z\)/\1/g" /data/wwwstats/xene/merged_log
# rid of the "T" between date and time
sed -ie "s/\([0-9]\{4\}\-[0-9]\{2\}\-[0-9]\{2\}\)T/\1 /g" /data/wwwstats/xene/merged_log
# rid of the port after the IPs
sed -ie 's/\([0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}\)\(\:[0-9]\{1,5\}\)/\1/g' /data/wwwstats/xene/merged_log

#sort each record in the log file by date and time
sort -k1 -k2 < /data/wwwstats/xene/merged_log > /data/wwwstats/xene/access_log 
